{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNneUppbLs7KXMhqQFb46nW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задача. Базовый синтаксис\n",
        "Открыть JSON-файл, проанализировать данные, изменить их и сохранить\n",
        "\n",
        "\n",
        "```\n",
        "Файл data.json:\n",
        "{\n",
        "  \"company\": \"TechCorp\",\n",
        "  \"departments\": {\n",
        "    \"dev\": [\"Alice\", \"Bob\"],\n",
        "    \"hr\": [\"Charlie\"]\n",
        "  },\n",
        "  \"budget\": 100000\n",
        "}\n",
        "```\n",
        "1. Прочитать JSON-файл в словарь data\n",
        "2. Итерировать по всем ключам верхнего уровня и вывести их\n",
        "3. Итерировать по всем значениям словаря departments\n",
        "4. Итерировать по парам ключ-значение в departments\n",
        "5. Добавить нового сотрудника \"David\" в отдел \"dev\"\n",
        "6. Увеличить бюджет на 10%\n",
        "7. Записать изменённый словарь обратно в файл\n",
        "\n"
      ],
      "metadata": {
        "id": "P6zlu42shS1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 1. Прочитать JSON-файл в словарь data\n",
        "with open('data.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# 2. Итерировать по всем ключам верхнего уровня и вывести их\n",
        "print(\"\\nКлючи верхнего уровня:\")\n",
        "for key in data.keys():\n",
        "    print(f\"- {key}\")\n",
        "\n",
        "# 3. Итерировать по всем значениям словаря departments\n",
        "print(\"\\nЗначения словаря departments:\")\n",
        "for value in data['departments'].values():\n",
        "    print(f\"- {value}\")\n",
        "\n",
        "# 4. Итерировать по парам ключ-значение в departments\n",
        "print(\"\\nПары ключ-значение в departments:\")\n",
        "for key, value in data['departments'].items():\n",
        "    print(f\"- {key}: {value}\")\n",
        "\n",
        "# 5. Добавить нового сотрудника \"David\" в отдел \"dev\"\n",
        "if 'dev' in data['departments']:\n",
        "    data['departments']['dev'].append('David')\n",
        "    print(f\"\\ndev после добавления сотрудника 'David': {data['departments']['dev']}\")\n",
        "\n",
        "# 6. Увеличить бюджет на 10%\n",
        "if 'budget' in data:\n",
        "    data['budget'] = data['budget'] * 1.1\n",
        "    print(f\"\\nБюджет увеличен на 10%. Новый бюджет: {data['budget']}\")\n",
        "\n",
        "# 7. Записать изменённый словарь обратно в файл\n",
        "with open('data.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(data, file, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Выводим итоговые данные для наглядности\n",
        "print(\"\\nИтоговые данные:\")\n",
        "print(json.dumps(data, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFUua5IRh1kS",
        "outputId": "2b686120-c021-4489-d574-cf6810633978"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ключи верхнего уровня:\n",
            "- company\n",
            "- departments\n",
            "- budget\n",
            "\n",
            "Значения словаря departments:\n",
            "- ['Alice', 'Bob', 'David', 'David']\n",
            "- ['Charlie']\n",
            "\n",
            "Пары ключ-значение в departments:\n",
            "- dev: ['Alice', 'Bob', 'David', 'David']\n",
            "- hr: ['Charlie']\n",
            "\n",
            "dev после добавления сотрудника 'David': ['Alice', 'Bob', 'David', 'David', 'David']\n",
            "\n",
            "Бюджет увеличен на 10%. Новый бюджет: 133100.00000000003\n",
            "\n",
            "Итоговые данные:\n",
            "{\n",
            "  \"company\": \"TechCorp\",\n",
            "  \"departments\": {\n",
            "    \"dev\": [\n",
            "      \"Alice\",\n",
            "      \"Bob\",\n",
            "      \"David\",\n",
            "      \"David\",\n",
            "      \"David\"\n",
            "    ],\n",
            "    \"hr\": [\n",
            "      \"Charlie\"\n",
            "    ]\n",
            "  },\n",
            "  \"budget\": 133100.00000000003\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 1: Анализ конфигурации модели NLP\n",
        "\n",
        "У вас есть конфигурационный файл для NLP-модели в виде словаря\n",
        "\n",
        "\n",
        "```\n",
        "config = {\n",
        "    \"model_name\": \"bert-base-uncased\",\n",
        "    \"batch_size\": 32,\n",
        "    \"max_length\": 128,\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"epochs\": 3,\n",
        "    \"labels\": [\"positive\", \"negative\", \"neutral\"]\n",
        "}\n",
        "```\n",
        "1. Получите значение learning_rate двумя способами: через скобки и через get()\n",
        "2. Добавьте новый параметр \"early_stopping\": True\n",
        "3. Измените batch_size на 64\n",
        "4. Пройдитесь по всем параметрам конфигурации и выведите только те, значения которых - числа\n",
        "5. Создайте копию конфигурации для тестирования с batch_size=8 и epochs=1\n"
      ],
      "metadata": {
        "id": "g9nBW1R8h2PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"model_name\": \"bert-base-uncased\",\n",
        "    \"batch_size\": 32,\n",
        "    \"max_length\": 128,\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"epochs\": 3,\n",
        "    \"labels\": [\"positive\", \"negative\", \"neutral\"]\n",
        "}\n",
        "\n",
        "# 1. Получите значение learning_rate двумя способами: через скобки и через get()\n",
        "print(\"\\n1. Получение learning_rate:\")\n",
        "lr1 = config[\"learning_rate\"]\n",
        "print(f\"Через скобки: {lr1}\")\n",
        "\n",
        "lr2 = config.get(\"learning_rate\")\n",
        "print(f\"Через get(): {lr2}\")\n",
        "\n",
        "# 2. Добавьте новый параметр \"early_stopping\": True\n",
        "config[\"early_stopping\"] = True\n",
        "print(f\"\\n2. early_stopping: {config['early_stopping']}\")\n",
        "\n",
        "# 3. Измените batch_size на 64\n",
        "config[\"batch_size\"] = 64\n",
        "print(f\"\\n3. batch_size: {config['batch_size']}\")\n",
        "\n",
        "# 4. Пройдитесь по всем параметрам конфигурации и выведите только те, значения которых - числа\n",
        "print(\"\\n4. Числовые параметры:\")\n",
        "for key, value in config.items():\n",
        "    if isinstance(value, (int, float)) and not isinstance(value, bool):\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# 5. Создайте копию конфигурации для тестирования с batch_size=8 и epochs=1\n",
        "\n",
        "test_config = dict(config)\n",
        "\n",
        "test_config[\"batch_size\"] = 8\n",
        "test_config[\"epochs\"] = 1\n",
        "\n",
        "print(\"\\n5. Тестовая конфигурация:\")\n",
        "for key, value in sorted(test_config.items()):\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTXbCgeViMeK",
        "outputId": "9ef03939-ccfe-46b7-b9f5-1d81d0fcec9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Получение learning_rate:\n",
            "Через скобки: 2e-05\n",
            "Через get(): 2e-05\n",
            "\n",
            "2. early_stopping: True\n",
            "\n",
            "3. batch_size: 64\n",
            "\n",
            "4. Числовые параметры:\n",
            "batch_size: 64\n",
            "max_length: 128\n",
            "learning_rate: 2e-05\n",
            "epochs: 3\n",
            "\n",
            "5. Тестовая конфигурация:\n",
            "batch_size: 8\n",
            "early_stopping: True\n",
            "epochs: 1\n",
            "labels: ['positive', 'negative', 'neutral']\n",
            "learning_rate: 2e-05\n",
            "max_length: 128\n",
            "model_name: bert-base-uncased\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 2: Обработка ответа от NLP-сервиса\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "api_response = {\n",
        "    \"text\": \"I really enjoyed the movie, the acting was amazing!\",\n",
        "    \"sentiment\": {\n",
        "        \"label\": \"positive\",\n",
        "        \"score\": 0.95,\n",
        "        \"confidence\": \"high\"\n",
        "    },\n",
        "    \"entities\": [\n",
        "        {\"entity\": \"movie\", \"type\": \"ENTERTAINMENT\", \"confidence\": 0.89},\n",
        "        {\"entity\": \"acting\", \"type\": \"SKILL\", \"confidence\": 0.92}\n",
        "    ],\n",
        "    \"language\": \"en\",\n",
        "    \"processed_in\": 0.45\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "1. Получите оценку тональности (score)\n",
        "2. Пройдитесь по всем сущностям (entities) и выведите только названия сущностей\n",
        "3. Найдите сущность с максимальной уверенностью (confidence)\n",
        "4. Добавьте в поле ответа \"model_version\": \"2.1.0\"\n",
        "5. Отфильтруйте все поля, значения которых являются строками"
      ],
      "metadata": {
        "id": "xf1UJKnaiSP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_response = {\n",
        "    \"text\": \"I really enjoyed the movie, the acting was amazing!\",\n",
        "    \"sentiment\": {\n",
        "        \"label\": \"positive\",\n",
        "        \"score\": 0.95,\n",
        "        \"confidence\": \"high\"\n",
        "    },\n",
        "    \"entities\": [\n",
        "        {\"entity\": \"movie\", \"type\": \"ENTERTAINMENT\", \"confidence\": 0.89},\n",
        "        {\"entity\": \"acting\", \"type\": \"SKILL\", \"confidence\": 0.92}\n",
        "    ],\n",
        "    \"language\": \"en\",\n",
        "    \"processed_in\": 0.45\n",
        "}\n",
        "# 1. Получите оценку тональности (score)\n",
        "sentiment_score = api_response[\"sentiment\"][\"score\"]\n",
        "print(f\"Оценка тональности: {sentiment_score}\")\n",
        "\n",
        "# 2. Пройдитесь по всем сущностям (entities) и выведите только названия сущностей\n",
        "entities = api_response[\"entities\"]\n",
        "entity_names = [entity[\"entity\"] for entity in entities]\n",
        "print(f\"Названия сущностей: {entity_names}\")\n",
        "\n",
        "# 3. Найдите сущность с максимальной уверенностью (confidence)\n",
        "max_confidence_entity = max(entities, key=lambda x: x[\"confidence\"])\n",
        "print(f\"Сущность с максимальной уверенностью: {max_confidence_entity}\")\n",
        "\n",
        "# 4. Создание нового объекта с добавленным полем \"model_version\"\n",
        "updated_response = api_response.copy()\n",
        "updated_response[\"model_version\"] = \"2.1.0\"\n",
        "\n",
        "# 5. Отфильтруйте все поля, значения которых являются строками\n",
        "filtered_response = {\n",
        "    key: value for key, value in updated_response.items()\n",
        "    if not isinstance(value, str)\n",
        "}\n",
        "\n",
        "# Итоговый результат\n",
        "print(f\"Исходный ответ с добавленным model_version:\")\n",
        "print(updated_response)\n",
        "print(f\"\\nОтфильтрованный ответ (без строковых значений):\")\n",
        "print(filtered_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlToFARGiiAr",
        "outputId": "b5aef5f1-5dea-4bb3-e963-502fa2aaab31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка тональности: 0.95\n",
            "Названия сущностей: ['movie', 'acting']\n",
            "Сущность с максимальной уверенностью: {'entity': 'acting', 'type': 'SKILL', 'confidence': 0.92}\n",
            "Исходный ответ с добавленным model_version:\n",
            "{'text': 'I really enjoyed the movie, the acting was amazing!', 'sentiment': {'label': 'positive', 'score': 0.95, 'confidence': 'high'}, 'entities': [{'entity': 'movie', 'type': 'ENTERTAINMENT', 'confidence': 0.89}, {'entity': 'acting', 'type': 'SKILL', 'confidence': 0.92}], 'language': 'en', 'processed_in': 0.45, 'model_version': '2.1.0'}\n",
            "\n",
            "Отфильтрованный ответ (без строковых значений):\n",
            "{'sentiment': {'label': 'positive', 'score': 0.95, 'confidence': 'high'}, 'entities': [{'entity': 'movie', 'type': 'ENTERTAINMENT', 'confidence': 0.89}, {'entity': 'acting', 'type': 'SKILL', 'confidence': 0.92}], 'processed_in': 0.45}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 3: Конфигурация пайплайна обработки текста\n",
        "\n",
        "\n",
        "```\n",
        "pipeline_config = {\n",
        "    \"steps\": {\n",
        "        \"tokenization\": {\"enabled\": True, \"method\": \"word\"},\n",
        "        \"stopwords\": {\"enabled\": True, \"language\": \"english\", \"custom_words\": []},\n",
        "        \"stemming\": {\"enabled\": False, \"algorithm\": \"porter\"},\n",
        "        \"normalization\": {\"enabled\": True, \"lowercase\": True, \"remove_punct\": True}\n",
        "    },\n",
        "    \"input_encoding\": \"utf-8\",\n",
        "    \"output_format\": \"tokens\"\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "1. Включите stemming, установив \"enabled\": True\n",
        "2. Добавьте \"numbers\" в custom_words для стоп-слов\n",
        "3. Получите список всех включенных шагов пайплайна\n",
        "4. Измените output_format на \"vectors\"\n",
        "5. Создайте упрощенную конфигурацию только с включенными шагами\n"
      ],
      "metadata": {
        "id": "cqFKJ8BzioTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = {\n",
        "    \"steps\": {\n",
        "        \"tokenization\": {\"enabled\": True, \"method\": \"word\"},\n",
        "        \"stopwords\": {\"enabled\": True, \"language\": \"english\", \"custom_words\": []},\n",
        "        \"stemming\": {\"enabled\": False, \"algorithm\": \"porter\"},\n",
        "        \"normalization\": {\"enabled\": True, \"lowercase\": True, \"remove_punct\": True}\n",
        "    },\n",
        "    \"input_encoding\": \"utf-8\",\n",
        "    \"output_format\": \"tokens\"\n",
        "}\n",
        "\n",
        "# 1. Включите stemming, установив \"enabled\": True\n",
        "pipeline_config[\"steps\"][\"stemming\"][\"enabled\"] = True\n",
        "\n",
        "# 2. Добавьте \"numbers\" в custom_words для стоп-слов\n",
        "pipeline_config[\"steps\"][\"stopwords\"][\"custom_words\"].append(\"numbers\")\n",
        "\n",
        "# 3. Получите список всех включенных шагов пайплайна\n",
        "enabled_steps = []\n",
        "for step_name, step_config in pipeline_config[\"steps\"].items():\n",
        "    if step_config.get(\"enabled\", False):\n",
        "        enabled_steps.append(step_name)\n",
        "\n",
        "# 4. Измените output_format на \"vectors\"\n",
        "pipeline_config[\"output_format\"] = \"vectors\"\n",
        "\n",
        "# 5. Создание упрощенной конфигурации только с включенными шагами\n",
        "simplified_config = {\n",
        "    \"input_encoding\": pipeline_config[\"input_encoding\"],\n",
        "    \"output_format\": pipeline_config[\"output_format\"],\n",
        "    \"steps\": {}\n",
        "}\n",
        "\n",
        "# Создайте упрощенную конфигурацию только с включенными шагами\n",
        "for step_name, step_config in pipeline_config[\"steps\"].items():\n",
        "    if step_config.get(\"enabled\", False):\n",
        "        simplified_config[\"steps\"][step_name] = step_config.copy()\n",
        "\n",
        "print(\"\\nОбновленная конфигурация:\")\n",
        "print(pipeline_config)\n",
        "print(\"\\nУпрощенная конфигурация (только включенные шаги):\")\n",
        "print(simplified_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgaCiSfqj3mE",
        "outputId": "332a7b04-2e29-4871-8728-a8f65fd6b4fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Обновленная конфигурация:\n",
            "{'steps': {'tokenization': {'enabled': True, 'method': 'word'}, 'stopwords': {'enabled': True, 'language': 'english', 'custom_words': ['numbers']}, 'stemming': {'enabled': True, 'algorithm': 'porter'}, 'normalization': {'enabled': True, 'lowercase': True, 'remove_punct': True}}, 'input_encoding': 'utf-8', 'output_format': 'vectors'}\n",
            "\n",
            "Упрощенная конфигурация (только включенные шаги):\n",
            "{'input_encoding': 'utf-8', 'output_format': 'vectors', 'steps': {'tokenization': {'enabled': True, 'method': 'word'}, 'stopwords': {'enabled': True, 'language': 'english', 'custom_words': ['numbers']}, 'stemming': {'enabled': True, 'algorithm': 'porter'}, 'normalization': {'enabled': True, 'lowercase': True, 'remove_punct': True}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 4: Агрегация статистики NLP-моделей\n",
        "\n",
        "\n",
        "```\n",
        "models_stats = {\n",
        "    \"bert-base\": {\n",
        "        \"accuracy\": 0.92,\n",
        "        \"f1_score\": 0.91,\n",
        "        \"inference_time\": 120,\n",
        "        \"size_mb\": 440\n",
        "    },\n",
        "    \"distilbert\": {\n",
        "        \"accuracy\": 0.89,\n",
        "        \"f1_score\": 0.88,\n",
        "        \"inference_time\": 65,\n",
        "        \"size_mb\": 250\n",
        "    },\n",
        "    \"roberta-large\": {\n",
        "        \"accuracy\": 0.94,\n",
        "        \"f1_score\": 0.93,\n",
        "        \"inference_time\": 210,\n",
        "        \"size_mb\": 1600\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "1. Найдите модель с максимальной точностью (accuracy)\n",
        "2. Рассчитайте среднее время инференса по всем моделям\n",
        "3. Создайте новый словарь только с метриками accuracy и f1_score для каждой модели\n",
        "4. Добавьте новую модель \"albert-base\" с данными: accuracy=0.87, f1_score=0.86, inference_time=55, size_mb=180\n",
        "5. Отфильтруйте модели, размер которых меньше 500 МБ\n"
      ],
      "metadata": {
        "id": "zRVVUy0pj384"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_stats = {\n",
        "    \"bert-base\": {\n",
        "        \"accuracy\": 0.92,\n",
        "        \"f1_score\": 0.91,\n",
        "        \"inference_time\": 120,\n",
        "        \"size_mb\": 440\n",
        "    },\n",
        "    \"distilbert\": {\n",
        "        \"accuracy\": 0.89,\n",
        "        \"f1_score\": 0.88,\n",
        "        \"inference_time\": 65,\n",
        "        \"size_mb\": 250\n",
        "    },\n",
        "    \"roberta-large\": {\n",
        "        \"accuracy\": 0.94,\n",
        "        \"f1_score\": 0.93,\n",
        "        \"inference_time\": 210,\n",
        "        \"size_mb\": 1600\n",
        "    }\n",
        "}\n",
        "\n",
        "# 1. Найдите модель с максимальной точностью (accuracy)\n",
        "max_accuracy_model = max(\n",
        "    models_stats.items(),\n",
        "    key=lambda item: item[1][\"accuracy\"]\n",
        ")\n",
        "print(f\"Модель с максимальной точностью: {max_accuracy_model[0]} (accuracy={max_accuracy_model[1]['accuracy']})\")\n",
        "\n",
        "# 2. Рассчитайте среднее время инференса по всем моделям\n",
        "inference_times = [stats[\"inference_time\"] for stats in models_stats.values()]\n",
        "average_inference_time = sum(inference_times) / len(inference_times)\n",
        "print(f\"Среднее время инференса: {average_inference_time:.2f} мс\")\n",
        "\n",
        "# 3. Создайте новый словарь только с метриками accuracy и f1_score для каждой модели\n",
        "metrics_only = {\n",
        "    model_name: {\n",
        "        \"accuracy\": stats[\"accuracy\"],\n",
        "        \"f1_score\": stats[\"f1_score\"]\n",
        "    }\n",
        "    for model_name, stats in models_stats.items()\n",
        "}\n",
        "print(f\"\\nСловарь только с accuracy и f1_score:\")\n",
        "print(metrics_only)\n",
        "\n",
        "# 4. Добавьте новую модель \"albert-base\" с данными: accuracy=0.87, f1_score=0.86, inference_time=55, size_mb=180\n",
        "models_stats[\"albert-base\"] = {\n",
        "    \"accuracy\": 0.87,\n",
        "    \"f1_score\": 0.86,\n",
        "    \"inference_time\": 55,\n",
        "    \"size_mb\": 180\n",
        "}\n",
        "print(f\"\\nПосле добавления albert-base:\")\n",
        "print(models_stats)\n",
        "\n",
        "# 5. Отфильтруйте модели, размер которых меньше 500 МБ\n",
        "filtered_models = {\n",
        "    model_name: stats\n",
        "    for model_name, stats in models_stats.items()\n",
        "    if stats[\"size_mb\"] < 500\n",
        "}\n",
        "print(f\"\\nМодели размером меньше 500 МБ:\")\n",
        "print(filtered_models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8JTCREakCQL",
        "outputId": "302fcd44-11f4-43fe-a2d8-6690e8592e1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель с максимальной точностью: roberta-large (accuracy=0.94)\n",
            "Среднее время инференса: 131.67 мс\n",
            "\n",
            "Словарь только с accuracy и f1_score:\n",
            "{'bert-base': {'accuracy': 0.92, 'f1_score': 0.91}, 'distilbert': {'accuracy': 0.89, 'f1_score': 0.88}, 'roberta-large': {'accuracy': 0.94, 'f1_score': 0.93}}\n",
            "\n",
            "После добавления albert-base:\n",
            "{'bert-base': {'accuracy': 0.92, 'f1_score': 0.91, 'inference_time': 120, 'size_mb': 440}, 'distilbert': {'accuracy': 0.89, 'f1_score': 0.88, 'inference_time': 65, 'size_mb': 250}, 'roberta-large': {'accuracy': 0.94, 'f1_score': 0.93, 'inference_time': 210, 'size_mb': 1600}, 'albert-base': {'accuracy': 0.87, 'f1_score': 0.86, 'inference_time': 55, 'size_mb': 180}}\n",
            "\n",
            "Модели размером меньше 500 МБ:\n",
            "{'bert-base': {'accuracy': 0.92, 'f1_score': 0.91, 'inference_time': 120, 'size_mb': 440}, 'distilbert': {'accuracy': 0.89, 'f1_score': 0.88, 'inference_time': 65, 'size_mb': 250}, 'albert-base': {'accuracy': 0.87, 'f1_score': 0.86, 'inference_time': 55, 'size_mb': 180}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 5: Работа с JSON-конфигом NLP-сервиса\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"service_name\": \"sentiment-analysis-api\",\n",
        "  \"version\": \"1.2.0\",\n",
        "  \"models\": {\n",
        "    \"sentiment\": {\n",
        "      \"path\": \"/models/bert-sentiment\",\n",
        "      \"max_input_length\": 512,\n",
        "      \"supported_languages\": [\"en\", \"es\", \"fr\"]\n",
        "    },\n",
        "    \"ner\": {\n",
        "      \"path\": \"/models/spacy-ner\",\n",
        "      \"max_input_length\": 1024,\n",
        "      \"supported_languages\": [\"en\"]\n",
        "    }\n",
        "  },\n",
        "  \"server\": {\n",
        "    \"host\": \"0.0.0.0\",\n",
        "    \"port\": 8080,\n",
        "    \"workers\": 4\n",
        "  },\n",
        "  \"rate_limit\": 100\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "1. Загрузите конфигурацию из JSON-файла\n",
        "2. Добавьте новую модель для \"summarization\" с соответствующими параметрами\n",
        "3. Увеличьте rate_limit на 50%\n",
        "4. Добавьте русский язык (\"ru\") в поддерживаемые языки для модели sentiment\n",
        "5. Создайте отдельный словарь только с настройками сервера\n",
        "6. Сохраните обновленную конфигурацию в новый файл nlp_service_config_updated.json\n"
      ],
      "metadata": {
        "id": "sQd6rYOskEhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 1. Загрузите конфигурацию из JSON-файла\n",
        "with open('nlp_service_config.json', 'r', encoding='utf-8') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# 2. Добавьте новую модель для \"summarization\" с соответствующими параметрами\n",
        "config[\"models\"][\"summarization\"] = {\n",
        "    \"path\": \"/models/bart-summarizer\",\n",
        "    \"max_input_length\": 1024,\n",
        "    \"supported_languages\": [\"en\", \"zh\", \"de\"]\n",
        "}\n",
        "\n",
        "# 3. Увеличьте rate_limit на 50%\n",
        "config[\"rate_limit\"] = int(config[\"rate_limit\"] * 1.5)\n",
        "\n",
        "# 4. Добавьте русский язык (\"ru\") в поддерживаемые языки для модели sentiment\n",
        "config[\"models\"][\"sentiment\"][\"supported_languages\"].append(\"ru\")\n",
        "\n",
        "# 5. Создайте отдельный словарь только с настройками сервера\n",
        "server_config = config[\"server\"].copy()\n",
        "\n",
        "# 6. Сохраните обновленную конфигурацию в новый файл nlp_service_config_updated.json\n",
        "with open('nlp_service_config_updated.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"1. Добавлена модель 'summarization': {'summarization' in config['models']}\")\n",
        "print(f\"2. Новый rate_limit: {config['rate_limit']}\")\n",
        "print(f\"3. Русский язык добавлен в sentiment: {'ru' in config['models']['sentiment']['supported_languages']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuuElbFikQfV",
        "outputId": "db0b49a4-6313-4975-a2b2-3ba8bd16b4ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Добавлена модель 'summarization': True\n",
            "2. Новый rate_limit: 150\n",
            "3. Русский язык добавлен в sentiment: True\n"
          ]
        }
      ]
    }
  ]
}