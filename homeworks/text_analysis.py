# -*- coding: utf-8 -*-
"""text_analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dLvSYnQJsG5w3lynRvYHX4YvpMOjN_Ki
"""

import re
from collections import Counter

def load_data(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        text = file.read()
    return text

def clean_text(text):
    cleaned_text = re.sub(r'<[^>]+>', '', text)
    cleaned_text = re.sub(r'[^a-zA-Zа-яА-ЯёЁ0-9\s.,!?:;-]', ' ', cleaned_text)
    cleaned_text = cleaned_text.lower()
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
    cleaned_text = cleaned_text.strip()
    return cleaned_text

def tokenize_text(text):
    tokens = text.split()
    return tokens

def get_word_frequencies(tokens):
    freq_dict = Counter(tokens)
    return freq_dict

def create_frequency_dict(tokens):
    return Counter(tokens)

if __name__ == "__main__":
    INPUT_FILE = "data.txt"
    OUTPUT_FILE = "analysis_results.txt"

    original_text = load_data(INPUT_FILE)
    print(f"1. Длина исходного текста: {len(original_text)} символов")
    cleaned_text = clean_text(original_text)
    print(f"2. Длина очищенного текста: {len(cleaned_text)} символов")
    tokens = tokenize_text(cleaned_text)
    print(f"3. Количество токенов (слов): {len(tokens)}")
    freq_dict = create_frequency_dict(tokens)
    print(f"4. Уникальных слов: {len(freq_dict)}")
    print(f"5. Общее количество слов: {sum(freq_dict.values())}")